{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments on Graph-Generative-Models\n",
    "In this notebook, we aim to evluate the performance of \"GDSS\" proposed in \"Score-based Generative Modeling of Graphs via the System of Stochastic Differential Equations\" (https://arxiv.org/pdf/2202.02514.pdf). The baseline model is tested on 3 datasets (Grid, Protein, 3D Point Cloud) and measured under 4 metrics (degree, clustering, orbit, spectral).\n",
    "\n",
    "It should be noted that we adopt the same datasets presets as in \"Efficient Graph Generation with Graph Recurrent Attention Networks\" (https://arxiv.org/pdf/1910.00760.pdf), where:\n",
    "- Grid: 100 graphs are generated with $100\\leq |V| \\leq 400$;\n",
    "- Protein: 918 graphs are generated with $100\\leq |V| \\leq 500$;\n",
    "- 3D Point-Cloud (FirstMM-DB): 41 graphs are generated with $\\bar{|V|} > 1000$\n",
    "\n",
    "Following the experimental setting as in \"GraphRNN: Generating Realistic Graphs with Deep Auto-regressive Models\" (https://arxiv.org/abs/1802.08773), we conduct a 80\\%-20\\% split of the graph samples in each dataset. Then we generate the same size of graph samples as the test dataset and harness the maximum mean discrepancy (MMD) to evaluate the generative graph distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment on GDSS\n",
    "Here we immigrate the original terminal-executable GDSS codes into the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Change current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = \"./GDSS/\"\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (4.38.0)\n",
      "Collecting molsets\n",
      "  Using cached molsets-0.3.1-py3-none-any.whl (51.6 MB)\n",
      "Requirement already satisfied: pyyaml in /usr/lib/python3/dist-packages (from -r requirements.txt (line 3)) (3.12)\n",
      "Collecting sklearn\n",
      "  Using cached sklearn-0.0.tar.gz (1.1 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pandas==1.1.5\n",
      "  Using cached pandas-1.1.5-cp36-cp36m-manylinux1_x86_64.whl (9.5 MB)\n",
      "Requirement already satisfied: cycler==0.10.0 in /usr/lib/python3/dist-packages (from -r requirements.txt (line 6)) (0.10.0)\n",
      "Collecting easydict==1.9\n",
      "  Using cached easydict-1.9.tar.gz (6.4 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement kiwisolver==1.3.2 (from versions: 0.1.0, 0.1.1, 0.1.2, 0.1.3, 1.0.0, 1.0.1, 1.1.0, 1.2.0, 1.3.0, 1.3.1)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for kiwisolver==1.3.2\u001b[0m\n",
      "\u001b[?25hCollecting package metadata (current_repodata.json): - ^C\n",
      "\\ \n",
      "Usage:   \n",
      "  pip install [options] <requirement specifier> [package-index-options] ...\n",
      "  pip install [options] -r <requirements file> [package-index-options] ...\n",
      "  pip install [options] [-e] <vcs project url> ...\n",
      "  pip install [options] [-e] <local project path> ...\n",
      "  pip install [options] <archive url/path> ...\n",
      "\n",
      "no such option: --user!\n",
      "yes: standard output: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt\n",
    "!conda install -c conda-forge rdkit=2020.09.1.0\n",
    "!yes | pip install git+https://github.com/fabriziocosta/EDeN.git --user!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Assign dataset and seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'grid'\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 289 544\n",
      "1 247 462\n",
      "2 247 462\n",
      "3 342 647\n",
      "4 140 256\n",
      "5 192 356\n",
      "6 169 312\n",
      "7 190 351\n",
      "8 154 283\n",
      "9 180 333\n",
      "10 255 478\n",
      "11 180 333\n",
      "12 224 418\n",
      "13 198 367\n",
      "14 198 367\n",
      "15 247 462\n",
      "16 130 237\n",
      "17 342 647\n",
      "18 289 544\n",
      "19 216 402\n",
      "20 342 647\n",
      "21 180 332\n",
      "22 192 356\n",
      "23 169 312\n",
      "24 210 391\n",
      "25 168 310\n",
      "26 120 218\n",
      "27 168 310\n",
      "28 306 577\n",
      "29 270 507\n",
      "30 221 412\n",
      "31 169 312\n",
      "32 240 449\n",
      "33 204 379\n",
      "34 110 199\n",
      "35 234 437\n",
      "36 170 313\n",
      "37 120 218\n",
      "38 180 333\n",
      "39 224 418\n",
      "40 130 237\n",
      "41 180 333\n",
      "42 323 610\n",
      "43 285 536\n",
      "44 198 367\n",
      "45 182 337\n",
      "46 306 577\n",
      "47 168 310\n",
      "48 204 379\n",
      "49 190 351\n",
      "50 266 499\n",
      "51 288 542\n",
      "52 288 542\n",
      "53 255 478\n",
      "54 240 449\n",
      "55 110 199\n",
      "56 190 351\n",
      "57 198 367\n",
      "58 143 262\n",
      "59 168 310\n",
      "60 165 304\n",
      "61 160 294\n",
      "62 120 218\n",
      "63 154 283\n",
      "64 323 610\n",
      "65 165 304\n",
      "66 225 420\n",
      "67 132 241\n",
      "68 170 313\n",
      "69 288 542\n",
      "70 224 418\n",
      "71 198 367\n",
      "72 110 199\n",
      "73 216 402\n",
      "74 247 462\n",
      "75 160 294\n",
      "76 132 241\n",
      "77 238 445\n",
      "78 221 412\n",
      "79 192 356\n",
      "80 180 333\n",
      "81 156 287\n",
      "82 285 536\n",
      "83 195 362\n",
      "84 192 356\n",
      "85 238 445\n",
      "86 190 351\n",
      "87 240 449\n",
      "88 306 577\n",
      "89 234 437\n",
      "90 234 437\n",
      "91 130 237\n",
      "92 285 536\n",
      "93 216 402\n",
      "94 196 364\n",
      "95 156 287\n",
      "96 170 313\n",
      "97 221 412\n",
      "98 288 542\n",
      "99 120 218\n",
      "342\n"
     ]
    }
   ],
   "source": [
    "!python data/data_generators.py --dataset $dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Decide which metric to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_selection = 'EMD'\n",
    "\n",
    "if metric_selection == 'EMD':\n",
    "    from sampler import Sampler, Sampler_mol\n",
    "    from evaluation.stats import eval_graph_list\n",
    "    from evaluation.mmd import gaussian, gaussian_emd\n",
    "else:\n",
    "    from sampler_new import Sampler, Sampler_mol\n",
    "    from evaluation.stats_new import eval_graph_list\n",
    "    import evaluation.mmd_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train the GDSS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import argparse\n",
    "import time\n",
    "from parsers.config import get_config\n",
    "from trainer import Trainer\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6,7\"\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "ts = time.strftime('%b%d-%H:%M:%S', time.gmtime())\n",
    "config = get_config(dataset, seed)\n",
    "trainer = Trainer(config) \n",
    "ckpt = trainer.train(ts)\n",
    "if 'sample' in config.keys():\n",
    "    config.ckpt = ckpt\n",
    "    sampler = Sampler(config) \n",
    "    sampler.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generate new graphs by the trained GDSS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./checkpoints/grid/Sep07-21:43:14.pth loaded\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Make Directory grid/test in Logs\n",
      "(Reverse)+(Langevin): eps=0.0001 denoise=True ema=True || snr=0.1 seps=0.7 n_steps=1 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "GEN SEED: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [05:21<05:21, 321.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Round 0 : 321.55s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [10:43<00:00, 321.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Round 1 : 322.11s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mdegree   \u001b[0m : \u001b[94m0.000000\u001b[0m\n",
      "\u001b[91mcluster  \u001b[0m : \u001b[94m0.000000\u001b[0m\n",
      "\u001b[91morbit    \u001b[0m : \u001b[94m1.000000\u001b[0m\n",
      "\u001b[91mspectral \u001b[0m : \u001b[94m0.000000\u001b[0m\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import argparse\n",
    "import time\n",
    "from parsers.config import get_config\n",
    "from trainer import Trainer\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6,7\"\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "config = get_config(dataset, seed)\n",
    "ckpt = 'Sep07-17:14:31'\n",
    "ckpt = 'Sep07-21:43:14'\n",
    "ckpt = 'grid_5000'\n",
    "config.ckpt = ckpt\n",
    "if dataset in ['QM9', 'ZINC250k']:\n",
    "    sampler = Sampler_mol(config)\n",
    "else:\n",
    "    sampler = Sampler(config) \n",
    "sampler.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load and calculate the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import math\n",
    "\n",
    "from utils.logger import Logger, set_log, start_log, train_log, sample_log, check_log\n",
    "from data.data_generators import load_dataset\n",
    "\n",
    "save_dir = './samples/pkl/grid/test/' + 'grid_5000.pkl'\n",
    "with open(save_dir, 'rb') as f:\n",
    "    gen_graph_list = pickle.load(f)\n",
    "\n",
    "test_split = 0.2\n",
    "\n",
    "graph_list = load_dataset(data_dir='./data', file_name='grid')\n",
    "test_size = int(test_split * len(graph_list))\n",
    "train_graph_list, test_graph_list = graph_list[test_size:], graph_list[:test_size]\n",
    "methods = ['degree', 'cluster', 'orbit', 'spectral'] \n",
    "kernels = {}\n",
    "if metric_selection == 'EMD':\n",
    "    kernels = {'degree':gaussian_emd, \n",
    "                'cluster':gaussian_emd, \n",
    "                'orbit':gaussian,\n",
    "                'spectral':gaussian_emd}\n",
    "    result_dict = eval_graph_list(test_graph_list, gen_graph_list, methods, kernels)\n",
    "else:\n",
    "    result_dict = eval_graph_list(test_graph_list, gen_graph_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c154a6e913370b3048d4224c64056db13e3907ff8e1125622ab77ec4e5033cc1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
