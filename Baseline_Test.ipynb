{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments on Graph-Generative-Models\n",
    "In this notebook, we aim to evluate the performance of \"GDSS\" proposed in \"Score-based Generative Modeling of Graphs via the System of Stochastic Differential Equations\" (https://arxiv.org/pdf/2202.02514.pdf). The baseline model is tested on 3 datasets (Grid, Protein, 3D Point Cloud) and measured under 4 metrics (degree, clustering, orbit, spectral).\n",
    "\n",
    "It should be noted that we adopt the same datasets presets as in \"Efficient Graph Generation with Graph Recurrent Attention Networks\" (https://arxiv.org/pdf/1910.00760.pdf), where:\n",
    "- Grid: 100 graphs are generated with $100\\leq |V| \\leq 400$;\n",
    "- Protein: 918 graphs are generated with $100\\leq |V| \\leq 500$;\n",
    "- 3D Point-Cloud (FirstMM-DB): 41 graphs are generated with $\\bar{|V|} > 1000$\n",
    "\n",
    "Following the experimental setting as in \"GraphRNN: Generating Realistic Graphs with Deep Auto-regressive Models\" (https://arxiv.org/abs/1802.08773), we conduct a 80\\%-20\\% split of the graph samples in each dataset. Then we generate the same size of graph samples as the test dataset and harness the maximum mean discrepancy (MMD) to evaluate the generative graph distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment on GDSS\n",
    "Here we immigrate the original terminal-executable GDSS codes into the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Change current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = \"./GDSS/\"\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /nethome/hsun409/anaconda3/envs/GDSS_env/lib/python3.7/site-packages (from -r requirements.txt (line 1)) (4.64.1)\n",
      "Requirement already satisfied: molsets in /nethome/hsun409/anaconda3/envs/GDSS_env/lib/python3.7/site-packages (from -r requirements.txt (line 2)) (0.3.1)\n",
      "Requirement already satisfied: pyyaml in /nethome/hsun409/anaconda3/envs/GDSS_env/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (6.0)\n",
      "Requirement already satisfied: sklearn in /nethome/hsun409/anaconda3/envs/GDSS_env/lib/python3.7/site-packages (from -r requirements.txt (line 4)) (0.0)\n",
      "Requirement already satisfied: pandas==1.1.5 in /nethome/hsun409/anaconda3/envs/GDSS_env/lib/python3.7/site-packages (from -r requirements.txt (line 5)) (1.1.5)\n",
      "Requirement already satisfied: cycler==0.10.0 in /nethome/hsun409/anaconda3/envs/GDSS_env/lib/python3.7/site-packages (from -r requirements.txt (line 6)) (0.10.0)\n",
      "Requirement already satisfied: easydict==1.9 in /nethome/hsun409/anaconda3/envs/GDSS_env/lib/python3.7/site-packages (from -r requirements.txt (line 7)) (1.9)\n",
      "Requirement already satisfied: kiwisolver==1.3.2 in /nethome/hsun409/anaconda3/envs/GDSS_env/lib/python3.7/site-packages (from -r requirements.txt (line 8)) (1.3.2)\n",
      "Requirement already satisfied: matplotlib==3.4.2 in /nethome/hsun409/anaconda3/envs/GDSS_env/lib/python3.7/site-packages (from -r requirements.txt (line 9)) (3.4.2)\n",
      "Requirement already satisfied: networkx==2.6.3 in /nethome/hsun409/anaconda3/envs/GDSS_env/lib/python3.7/site-packages (from -r requirements.txt (line 10)) (2.6.3)\n",
      "Requirement already satisfied: numpy==1.20.3 in /nethome/hsun409/anaconda3/envs/GDSS_env/lib/python3.7/site-packages (from -r requirements.txt (line 11)) (1.20.3)\n",
      "Requirement already satisfied: pyparsing==2.4.7 in /nethome/hsun409/anaconda3/envs/GDSS_env/lib/python3.7/site-packages (from -r requirements.txt (line 12)) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil==2.8.2 in /nethome/hsun409/anaconda3/envs/GDSS_env/lib/python3.7/site-packages (from -r requirements.txt (line 13)) (2.8.2)\n",
      "Collecting scipy==1.7.1\n",
      "  Using cached scipy-1.7.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (28.5 MB)\n",
      "Requirement already satisfied: six==1.16.0 in /nethome/hsun409/anaconda3/envs/GDSS_env/lib/python3.7/site-packages (from -r requirements.txt (line 15)) (1.16.0)\n",
      "Requirement already satisfied: pyemd==0.5.1 in /nethome/hsun409/anaconda3/envs/GDSS_env/lib/python3.7/site-packages (from -r requirements.txt (line 16)) (0.5.1)\n",
      "Requirement already satisfied: requests in /nethome/hsun409/anaconda3/envs/GDSS_env/lib/python3.7/site-packages (from -r requirements.txt (line 17)) (2.28.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /nethome/hsun409/anaconda3/envs/GDSS_env/lib/python3.7/site-packages (from pandas==1.1.5->-r requirements.txt (line 5)) (2022.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /nethome/hsun409/anaconda3/envs/GDSS_env/lib/python3.7/site-packages (from matplotlib==3.4.2->-r requirements.txt (line 9)) (9.2.0)\n",
      "Requirement already satisfied: seaborn>=0.9.0 in /nethome/hsun409/anaconda3/envs/GDSS_env/lib/python3.7/site-packages (from molsets->-r requirements.txt (line 2)) (0.12.0)\n",
      "Requirement already satisfied: torch>=1.1.0 in /nethome/hsun409/anaconda3/envs/GDSS_env/lib/python3.7/site-packages (from molsets->-r requirements.txt (line 2)) (1.12.1)\n",
      "Requirement already satisfied: pomegranate==0.12.0 in /nethome/hsun409/anaconda3/envs/GDSS_env/lib/python3.7/site-packages (from molsets->-r requirements.txt (line 2)) (0.12.0)\n",
      "Requirement already satisfied: fcd-torch>=1.0.5 in /nethome/hsun409/anaconda3/envs/GDSS_env/lib/python3.7/site-packages (from molsets->-r requirements.txt (line 2)) (1.0.7)\n",
      "Requirement already satisfied: joblib>=0.9.0b4 in /nethome/hsun409/anaconda3/envs/GDSS_env/lib/python3.7/site-packages (from pomegranate==0.12.0->molsets->-r requirements.txt (line 2)) (1.1.0)\n",
      "Requirement already satisfied: scikit-learn in /nethome/hsun409/anaconda3/envs/GDSS_env/lib/python3.7/site-packages (from sklearn->-r requirements.txt (line 4)) (1.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /nethome/hsun409/anaconda3/envs/GDSS_env/lib/python3.7/site-packages (from requests->-r requirements.txt (line 17)) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /nethome/hsun409/anaconda3/envs/GDSS_env/lib/python3.7/site-packages (from requests->-r requirements.txt (line 17)) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /nethome/hsun409/anaconda3/envs/GDSS_env/lib/python3.7/site-packages (from requests->-r requirements.txt (line 17)) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /nethome/hsun409/anaconda3/envs/GDSS_env/lib/python3.7/site-packages (from requests->-r requirements.txt (line 17)) (1.26.12)\n",
      "Requirement already satisfied: typing_extensions in /nethome/hsun409/anaconda3/envs/GDSS_env/lib/python3.7/site-packages (from seaborn>=0.9.0->molsets->-r requirements.txt (line 2)) (3.7.4.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /nethome/hsun409/anaconda3/envs/GDSS_env/lib/python3.7/site-packages (from scikit-learn->sklearn->-r requirements.txt (line 4)) (3.1.0)\n",
      "Installing collected packages: scipy\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.7.3\n",
      "    Uninstalling scipy-1.7.3:\n",
      "      Successfully uninstalled scipy-1.7.3\n",
      "Successfully installed scipy-1.7.1\n",
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "Retrieving notices: ...working... done\n",
      "\n",
      "Usage:   \n",
      "  pip install [options] <requirement specifier> [package-index-options] ...\n",
      "  pip install [options] -r <requirements file> [package-index-options] ...\n",
      "  pip install [options] [-e] <vcs project url> ...\n",
      "  pip install [options] [-e] <local project path> ...\n",
      "  pip install [options] <archive url/path> ...\n",
      "\n",
      "no such option: --user!\n",
      "yes: standard output: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt\n",
    "!conda install -c conda-forge rdkit=2020.09.1.0\n",
    "!yes | pip install git+https://github.com/fabriziocosta/EDeN.git --user!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Assign dataset and seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'grid'\n",
    "dataset = 'DD'\n",
    "# dataset = 'FIRSTMM_DB'\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install GPUtil\n",
    "\n",
    "import torch\n",
    "from GPUtil import showUtilization as gpu_usage\n",
    "from numba import cuda\n",
    "\n",
    "def free_gpu_cache():\n",
    "    print(\"Initial GPU Usage\")\n",
    "    gpu_usage()                             \n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    cuda.select_device(0)\n",
    "    cuda.close()\n",
    "    cuda.select_device(0)\n",
    "\n",
    "    print(\"GPU Usage after emptying the cache\")\n",
    "    gpu_usage()\n",
    "\n",
    "free_gpu_cache()                           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading graph dataset: FIRSTMM_DB\n",
      "56468\n",
      "126038\n",
      "Graphs loaded, total num: 24\n",
      "FIRSTMM_DB 24\n",
      "995\n"
     ]
    }
   ],
   "source": [
    "!python data/data_generators.py --dataset $dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Decide which metric to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_selection = 'EMD'\n",
    "\n",
    "if metric_selection == 'EMD':\n",
    "    from sampler import Sampler, Sampler_mol\n",
    "    from evaluation.stats import eval_graph_list\n",
    "    from evaluation.mmd import gaussian, gaussian_emd\n",
    "else:\n",
    "    from sampler_new import Sampler, Sampler_mol\n",
    "    from evaluation.stats_new import eval_graph_list\n",
    "    import evaluation.mmd_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train the GDSS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import argparse\n",
    "import time\n",
    "from parsers.config import get_config\n",
    "from trainer import Trainer\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6,7\"\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "ts = time.strftime('%b%d-%H:%M:%S', time.gmtime())\n",
    "config = get_config(dataset, seed)\n",
    "trainer = Trainer(config) \n",
    "ckpt = trainer.train(ts)\n",
    "if 'sample' in config.keys():\n",
    "    config.ckpt = ckpt\n",
    "    sampler = Sampler(config) \n",
    "    sampler.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generate new graphs by the trained GDSS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./checkpoints/DD/DD_1500.pth loaded\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Make Directory DD/test in Logs\n",
      "(Reverse)+(Langevin): eps=0.0001 denoise=True ema=True || snr=0.1 seps=0.7 n_steps=1 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "GEN SEED: 13\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9658/862765514.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/mnt/284ac980-b350-4035-8e02-707f671ad89e/hsun409/Experiments-on-Graph-Generative-Models/GDSS/sampler.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mt_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_flags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_flags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_graph_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfigt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampling_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_adj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_flags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/284ac980-b350-4035-8e02-707f671ad89e/hsun409/Experiments-on-Graph-Generative-Models/GDSS/utils/graph_utils.py\u001b[0m in \u001b[0;36minit_flags\u001b[0;34m(graph_list, config, batch_size)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mmax_node_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_node_num\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0mgraph_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraphs_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_node_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m     \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mflags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode_flags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import argparse\n",
    "import time\n",
    "from parsers.config import get_config\n",
    "from trainer import Trainer\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2,5,6,7\"\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "config = get_config(dataset, seed)\n",
    "ckpt = 'grid_5000'\n",
    "ckpt = 'DD_1500'\n",
    "config.ckpt = ckpt\n",
    "if dataset in ['QM9', 'ZINC250k']:\n",
    "    sampler = Sampler_mol(config)\n",
    "else:\n",
    "    sampler = Sampler(config) \n",
    "sampler.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load and calculate the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target dataset:DD\n",
      "Shape of testing dataset:233\n",
      "Shape of gen dataset:233\n",
      "\u001b[91mdegree   \u001b[0m : \u001b[94m0.46610833\u001b[0m\n",
      "\u001b[91mcluster  \u001b[0m : \u001b[94m0.52482759\u001b[0m\n",
      "\u001b[91morbit    \u001b[0m : \u001b[94m0.96940001\u001b[0m\n",
      "\u001b[91mspectral \u001b[0m : \u001b[94m0.45129634\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import math\n",
    "\n",
    "from utils.logger import Logger, set_log, start_log, train_log, sample_log, check_log\n",
    "from data.data_generators import load_dataset\n",
    "\n",
    "save_dir = './samples/pkl/grid/test/' + 'grid_5000.pkl'\n",
    "save_dir = './samples/pkl/DD/test/Sep09-17:57:49_500-sample.pkl'\n",
    "# save_dir = './samples/pkl/DD/test/DD_1000-sample.pkl'\n",
    "with open(save_dir, 'rb') as f:\n",
    "    gen_graph_list = pickle.load(f)\n",
    "\n",
    "test_split = 0.2\n",
    "\n",
    "graph_list = load_dataset(data_dir='./data', file_name=dataset)\n",
    "print('Target dataset:' + dataset)\n",
    "test_size = int(test_split * len(graph_list))\n",
    "train_graph_list, test_graph_list = graph_list[test_size:], graph_list[:test_size]\n",
    "print('Length of testing dataset:' + str(len(test_graph_list)))\n",
    "print('Length of gen dataset:' + str(len(gen_graph_list)))\n",
    "methods = ['degree', 'cluster', 'orbit', 'spectral'] \n",
    "kernels = {}\n",
    "if metric_selection == 'EMD':\n",
    "    kernels = {'degree':gaussian_emd, \n",
    "                'cluster':gaussian_emd, \n",
    "                'orbit':gaussian,\n",
    "                'spectral':gaussian_emd}\n",
    "    result_dict = eval_graph_list(test_graph_list, gen_graph_list, methods, kernels)\n",
    "else:\n",
    "    result_dict = eval_graph_list(test_graph_list, gen_graph_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c154a6e913370b3048d4224c64056db13e3907ff8e1125622ab77ec4e5033cc1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
