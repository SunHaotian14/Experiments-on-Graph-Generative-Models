{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments on Graph-Generative-Models\n",
    "In this notebook, we aim to evluate the performance of \"GDSS\" proposed in \"Score-based Generative Modeling of Graphs via the System of Stochastic Differential Equations\" (https://arxiv.org/pdf/2202.02514.pdf). The baseline model is tested on 3 datasets (Grid, Protein, 3D Point Cloud) and measured under 4 metrics (degree, clustering, orbit, spectral).\n",
    "\n",
    "It should be noted that we adopt the same datasets presets as in \"Efficient Graph Generation with Graph Recurrent Attention Networks\" (https://arxiv.org/pdf/1910.00760.pdf), where:\n",
    "- Grid: 100 graphs are generated with $100\\leq |V| \\leq 400$;\n",
    "- Protein: 918 graphs are generated with $100\\leq |V| \\leq 500$;\n",
    "- 3D Point-Cloud (FirstMM-DB): 41 graphs are generated with $\\bar{|V|} > 1000$\n",
    "\n",
    "Following the experimental setting as in \"GraphRNN: Generating Realistic Graphs with Deep Auto-regressive Models\" (https://arxiv.org/abs/1802.08773), we conduct a 80\\%-20\\% split of the graph samples in each dataset. Then we generate the same size of graph samples as the test dataset and harness the maximum mean discrepancy (MMD) to evaluate the generative graph distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment on GDSS\n",
    "Here we immigrate the original terminal-executable GDSS codes into the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Change current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = \"./GDSS/\"\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (4.38.0)\n",
      "Collecting molsets\n",
      "  Using cached molsets-0.3.1-py3-none-any.whl (51.6 MB)\n",
      "Requirement already satisfied: pyyaml in /usr/lib/python3/dist-packages (from -r requirements.txt (line 3)) (3.12)\n",
      "Collecting sklearn\n",
      "  Using cached sklearn-0.0.tar.gz (1.1 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pandas==1.1.5\n",
      "  Using cached pandas-1.1.5-cp36-cp36m-manylinux1_x86_64.whl (9.5 MB)\n",
      "Requirement already satisfied: cycler==0.10.0 in /usr/lib/python3/dist-packages (from -r requirements.txt (line 6)) (0.10.0)\n",
      "Collecting easydict==1.9\n",
      "  Using cached easydict-1.9.tar.gz (6.4 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement kiwisolver==1.3.2 (from versions: 0.1.0, 0.1.1, 0.1.2, 0.1.3, 1.0.0, 1.0.1, 1.1.0, 1.2.0, 1.3.0, 1.3.1)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for kiwisolver==1.3.2\u001b[0m\n",
      "\u001b[?25hCollecting package metadata (current_repodata.json): - ^C\n",
      "\\ \n",
      "Usage:   \n",
      "  pip install [options] <requirement specifier> [package-index-options] ...\n",
      "  pip install [options] -r <requirements file> [package-index-options] ...\n",
      "  pip install [options] [-e] <vcs project url> ...\n",
      "  pip install [options] [-e] <local project path> ...\n",
      "  pip install [options] <archive url/path> ...\n",
      "\n",
      "no such option: --user!\n",
      "yes: standard output: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt\n",
    "!conda install -c conda-forge rdkit=2020.09.1.0\n",
    "!yes | pip install git+https://github.com/fabriziocosta/EDeN.git --user!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Assign dataset and seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'grid'\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 289 544\n",
      "1 247 462\n",
      "2 247 462\n",
      "3 342 647\n",
      "4 140 256\n",
      "5 192 356\n",
      "6 169 312\n",
      "7 190 351\n",
      "8 154 283\n",
      "9 180 333\n",
      "10 255 478\n",
      "11 180 333\n",
      "12 224 418\n",
      "13 198 367\n",
      "14 198 367\n",
      "15 247 462\n",
      "16 130 237\n",
      "17 342 647\n",
      "18 289 544\n",
      "19 216 402\n",
      "20 342 647\n",
      "21 180 332\n",
      "22 192 356\n",
      "23 169 312\n",
      "24 210 391\n",
      "25 168 310\n",
      "26 120 218\n",
      "27 168 310\n",
      "28 306 577\n",
      "29 270 507\n",
      "30 221 412\n",
      "31 169 312\n",
      "32 240 449\n",
      "33 204 379\n",
      "34 110 199\n",
      "35 234 437\n",
      "36 170 313\n",
      "37 120 218\n",
      "38 180 333\n",
      "39 224 418\n",
      "40 130 237\n",
      "41 180 333\n",
      "42 323 610\n",
      "43 285 536\n",
      "44 198 367\n",
      "45 182 337\n",
      "46 306 577\n",
      "47 168 310\n",
      "48 204 379\n",
      "49 190 351\n",
      "50 266 499\n",
      "51 288 542\n",
      "52 288 542\n",
      "53 255 478\n",
      "54 240 449\n",
      "55 110 199\n",
      "56 190 351\n",
      "57 198 367\n",
      "58 143 262\n",
      "59 168 310\n",
      "60 165 304\n",
      "61 160 294\n",
      "62 120 218\n",
      "63 154 283\n",
      "64 323 610\n",
      "65 165 304\n",
      "66 225 420\n",
      "67 132 241\n",
      "68 170 313\n",
      "69 288 542\n",
      "70 224 418\n",
      "71 198 367\n",
      "72 110 199\n",
      "73 216 402\n",
      "74 247 462\n",
      "75 160 294\n",
      "76 132 241\n",
      "77 238 445\n",
      "78 221 412\n",
      "79 192 356\n",
      "80 180 333\n",
      "81 156 287\n",
      "82 285 536\n",
      "83 195 362\n",
      "84 192 356\n",
      "85 238 445\n",
      "86 190 351\n",
      "87 240 449\n",
      "88 306 577\n",
      "89 234 437\n",
      "90 234 437\n",
      "91 130 237\n",
      "92 285 536\n",
      "93 216 402\n",
      "94 196 364\n",
      "95 156 287\n",
      "96 170 313\n",
      "97 221 412\n",
      "98 288 542\n",
      "99 120 218\n",
      "342\n"
     ]
    }
   ],
   "source": [
    "!python data/data_generators.py --dataset $dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train the GDSS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Make Directory grid/test in Logs\n",
      "\u001b[91mSep07-17:14:31\u001b[0m\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[grid]   init=deg (5)   seed=42   batch_size=16\n",
      "----------------------------------------------------------------------------------------------------\n",
      "lr=0.01 schedule=True ema=0.999 epochs=2500 reduce=False eps=1e-05\n",
      "(ScoreNetworkX)+(ScoreNetworkA=GCN,4)   : depth=5 adim=32 nhid=32 layers=7 linears=2 c=(2 8 4)\n",
      "(x:VP)=(0.10, 1.00) N=1000 (adj:VP)=(0.20, 0.80) N=1000\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch]:  40%|████      | 1000/2500 [43:32<1:07:02,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 1000] test adj: 1.277e+03 | train adj: 1.043e+03 | test x: 4.095e+01 | train x: 3.764e+01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch]:  80%|████████  | 2000/2500 [1:27:07<21:48,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 2000] test adj: 1.126e+03 | train adj: 9.687e+02 | test x: 4.875e+01 | train x: 3.544e+01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch]:  95%|█████████▌| 2376/2500 [1:43:23<05:32,  2.68s/it]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import argparse\n",
    "import time\n",
    "from parsers.config import get_config\n",
    "from trainer import Trainer\n",
    "from sampler import Sampler, Sampler_mol\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6,7\"\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "ts = time.strftime('%b%d-%H:%M:%S', time.gmtime())\n",
    "config = get_config(dataset, seed)\n",
    "trainer = Trainer(config) \n",
    "ckpt = trainer.train(ts)\n",
    "if 'sample' in config.keys():\n",
    "    config.ckpt = ckpt\n",
    "    sampler = Sampler(config) \n",
    "    sampler.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generate new graphs by the trained GDSS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./checkpoints/grid/Sep07-17:14:31.pth loaded\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Make Directory grid/test in Logs\n",
      "(Reverse)+(Langevin): eps=0.0001 denoise=True ema=True || snr=0.1 seps=0.7 n_steps=1 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "GEN SEED: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [05:40<05:40, 340.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Round 0 : 340.84s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [11:19<00:00, 339.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Round 1 : 338.57s\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'gaussian_tv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1127/1160584702.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/mnt/284ac980-b350-4035-8e02-707f671ad89e/hsun409/Experiments-on-Graph-Generative-Models/GDSS/sampler.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;31m# -------- Evaluation --------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mmethods\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_eval_settings_mod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mresult_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_graph_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_graph_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_graph_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethods\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethods\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkernels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'MMD_full {result_dict}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'='\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/284ac980-b350-4035-8e02-707f671ad89e/hsun409/Experiments-on-Graph-Generative-Models/GDSS/evaluation/stats_new.py\u001b[0m in \u001b[0;36meval_graph_list\u001b[0;34m(graph_ref_list, graph_pred_list, methods, kernels)\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMETHOD_NAME_TO_FUNC\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_ref_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_pred_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m             \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMETHOD_NAME_TO_FUNC\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_ref_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_pred_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\033[91m'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34mf'{method:9s}'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\033[0m'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' : '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\033[94m'\u001b[0m \u001b[0;34m+\u001b[0m  \u001b[0;34mf'{results[method]:.6f}'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\033[0m'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/284ac980-b350-4035-8e02-707f671ad89e/hsun409/Experiments-on-Graph-Generative-Models/GDSS/evaluation/stats_new.py\u001b[0m in \u001b[0;36mdegree_stats\u001b[0;34m(graph_ref_list, graph_pred_list, is_parallel)\u001b[0m\n\u001b[1;32m     53\u001b[0m           nx.degree_histogram(graph_pred_list_remove_empty[i]))\n\u001b[1;32m     54\u001b[0m       \u001b[0msample_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdegree_temp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m   \u001b[0mmmd_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_mmd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_ref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgaussian_tv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0melapsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mprev\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gaussian_tv' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import argparse\n",
    "import time\n",
    "from parsers.config import get_config\n",
    "from trainer import Trainer\n",
    "from sampler import Sampler, Sampler_mol\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "config = get_config(dataset, seed)\n",
    "ckpt = 'Sep07-17:14:31'\n",
    "config.ckpt = ckpt\n",
    "if dataset in ['QM9', 'ZINC250k']:\n",
    "    sampler = Sampler_mol(config)\n",
    "else:\n",
    "    sampler = Sampler(config) \n",
    "sampler.sample()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c154a6e913370b3048d4224c64056db13e3907ff8e1125622ab77ec4e5033cc1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
