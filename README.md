# Experiments on Graph-Generative-Models
## Overview

This notebook is a test of the baseline models for the graph generative models. The baseline models are the following:

- GraphAF: [“GraphAF: a Flow-based Autoregressive Model for Molecular Graph Generation”](https://arxiv.org/abs/2001.09382)
- GraphDF: [“GraphDF: A Discrete Flow Model for Molecular Graph Generation”](https://arxiv.org/abs/2102.01189)
- GDSS: [“Score-based Generative Modeling of Graphs via the System of Stochastic Differential Equations”](https://arxiv.org/abs/2202.02514)

The baseline models are tested on several datasets and measured under 4 metrics (*degree, clustering, orbit, spectral*).

The generic graph datasets are:
- Grid: 100 graphs are generated with $100\leq |V| \leq 400$;
- Community-small: 100 graphs are generated with $12\leq |V| \leq 20$;
- Grid: 100 graphs are generated with $100\leq |V| \leq 400$;
- Caveman: 200 graphs are generated with $5\leq |V| \leq 10$;
- Cora: 200 graphs are generated with $9\leq |V| \leq 87$;
- Breast: 100 graphs are generated with $12\leq |V| \leq 18$;
- Ego-small: 200 graphs are generated with $4\leq |V| \leq 18$;
- ~~Protein: 918 graphs are generated with $100\leq |V| \leq 500$;~~
- ~~3D Point-Cloud (FirstMM-DB): 41 graphs are generated with $\bar{|V|} > 1000$~~

Following the experimental setting as in ["GraphRNN: Generating Realistic Graphs with Deep Auto-regressive Models"](https://arxiv.org/abs/1802.08773), we conduct a 80\%-20\% split of the graph samples in each dataset. Then we generate the same size of graph samples as the test dataset and harness the maximum mean discrepancy (MMD) to evaluate the generative graph distribution.

## Discussion on Metrics Kernel

- In [GDSS](https://arxiv.org/abs/2202.02514), the authors use the Gaussian Earth Mover’s Distance (EMD) kernel to compute the MMDs instead of the total variation (TV) distance, since the TV distance leads to an indefinite kernel and an undefined behavior.
- Quoted from ["Efficient Graph Generation with Graph Recurrent Attention Networks"](https://arxiv.org/pdf/1910.00760.pdf)In practice, we found computing this MMD with the Gaussian EMD kernel to be very slow for moderately large graphs. Therefore, we use the total variation (TV) distance, which greatly speeds up the evaluation and is still consistent with EMD. 
- In this test, both EMD and MMD kernels are adopted, with an option given to determine which one to use.

## Issues with NetworkX Versions

The latest versions of NetworkX (2.x) is not completely compatible with the the 1.x versions. Some of the datasets provided are generated with the 1.x versions. However, since the GraphAF and GraphDF are implemented with the 2.x versions, the datasets need to be converted to the 2.x versions. The conversion is done in the following part.

## Experiments
### Experiment on GDSS
GDSS is a score-based generative model for graphs. The node feature vectors and the adjancency matrix are generated by the system of stochastic differential equations (SDEs). For the better control flow, we immigrate the original terminal-executable GDSS codes into the notebook.

For more details, see GDSS: [“Score-based Generative Modeling of Graphs via the System of Stochastic Differential Equations”](https://arxiv.org/abs/2202.02514). 

The code modifies based on [GDSS's Github Repo](https://github.com/harryjo97/GDSS).

### Experiment on GraphAF / GraphDF
Here we investigate the performance on GraphAF / GraphDF. These two models are autoregressive flow-based models.

For more details, see GraphAF: [“GraphAF: a Flow-based Autoregressive Model for Molecular Graph Generation”](https://arxiv.org/abs/2001.09382) and GraphDF: [“GraphDF: A Discrete Flow Model for Molecular Graph Generation”](https://arxiv.org/abs/2102.01189).

The codes are modified based on the [DIG library](https://github.com/divelab/DIG).